{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ML1_1:\n",
        "https://www.hackerrank.com/challenges/capturing-non-capturing-groups/problem?isFullScreen=true"
      ],
      "metadata": {
        "id": "7lpiE-yL_CBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Regex_Pattern = r'okokok'"
      ],
      "metadata": {
        "id": "cig3wVqJ_EOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML1_2:\n",
        "https://www.hackerrank.com/challenges/branch-reset-groups/problem?isFullScreen=true\n"
      ],
      "metadata": {
        "id": "1CWyAJyS_O4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$Regex_Pattern = '^(\\d{2}((---)|(-)|(.)|(:))){3}';"
      ],
      "metadata": {
        "id": "ePA9JV-Y_X-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP5:\n",
        "классная работа, задача 5: нужно сделать на нашем датасет data сначала лемматизацию, потом стемминг и наоборот"
      ],
      "metadata": {
        "id": "157U23KGDRJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade nltk gensim bokeh umap-learn\n",
        "\n",
        "import itertools\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import umap\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONrwZWnjFqpb",
        "outputId": "d8ad65b7-fc53-4030-eeba-48b14ca2075d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.8)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (4.3.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.8/dist-packages (3.0.3)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.8/dist-packages (0.5.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: FuzzyTM>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (2.0.5)\n",
            "Requirement already satisfied: pyfume in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (1.3.5)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.8/dist-packages (from bokeh) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh) (6.0.4)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.8/dist-packages (from bokeh) (1.0.6)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.8/dist-packages (from bokeh) (21.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh) (6.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.8/dist-packages (from bokeh) (2022.9.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=16.8->bokeh) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.5.8)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (5.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (3.11.0)\n",
            "Requirement already satisfied: simpful in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
            "Requirement already satisfied: fst-pso in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
            "Requirement already satisfied: miniful in /usr/local/lib/python3.8/dist-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выгружаем датасет:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt -nc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOdFMZCbH48Y",
        "outputId": "402aac5f-f302-496f-c677-8bbc5d12e2a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-22 00:02:33--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/obaitrix9jyu84r/quora.txt [following]\n",
            "--2022-12-22 00:02:34--  https://www.dropbox.com/s/dl/obaitrix9jyu84r/quora.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2825f8c09236dc46aaf32326fb.dl.dropboxusercontent.com/cd/0/get/BzE3W8mPZNx4EC15C6RvCXYYX5-70lI9eDwxrrHvz3aw-RdJRWJXhXoMCaQN-TYiorDp4-GZez8rAV2EBD4ZvfXAiXdC8YwobVwt_mleSSC5bKBI8J4s6Opfl3Am3nIq3EEKGXXGXu1PfQN4sjKTi9mxg92Hl3MPZF0wYkK_MaQeTQ/file?dl=1# [following]\n",
            "--2022-12-22 00:02:34--  https://uc2825f8c09236dc46aaf32326fb.dl.dropboxusercontent.com/cd/0/get/BzE3W8mPZNx4EC15C6RvCXYYX5-70lI9eDwxrrHvz3aw-RdJRWJXhXoMCaQN-TYiorDp4-GZez8rAV2EBD4ZvfXAiXdC8YwobVwt_mleSSC5bKBI8J4s6Opfl3Am3nIq3EEKGXXGXu1PfQN4sjKTi9mxg92Hl3MPZF0wYkK_MaQeTQ/file?dl=1\n",
            "Resolving uc2825f8c09236dc46aaf32326fb.dl.dropboxusercontent.com (uc2825f8c09236dc46aaf32326fb.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc2825f8c09236dc46aaf32326fb.dl.dropboxusercontent.com (uc2825f8c09236dc46aaf32326fb.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33813903 (32M) [application/binary]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt         100%[===================>]  32.25M  20.2MB/s    in 1.6s    \n",
            "\n",
            "2022-12-22 00:02:37 (20.2 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_XkVZQZFJJiz",
        "outputId": "407f2833-a895-4a94-e158-f13e5de8a79a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What TV shows or books help you read people's body language?\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "3g71jAlsH4-w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_tok = [tokenizer.tokenize(data[x].lower()) for x in range(0, len(data), 1)]\n",
        "print (data_tok[456123])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gggg4_ZuIozy",
        "outputId": "2006c928-866e-4da7-d500-a00a1da40854"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['how', 'do', 'i', 'stop', 'my', 'american', 'staffy', '/', 'kelpie', 'mix', 'from', 'biting', 'its', 'tail', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for i in data_tok:\n",
        "  for j in i:\n",
        "    all_words.append(j)\n",
        "unique_words = set(all_words)"
      ],
      "metadata": {
        "id": "CF4_4L_ONH8N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_of_lem = []\n",
        "\n",
        "for i in all_words:\n",
        "  stem_of_lem.append(ps.stem(lemmatizer.lemmatize(i)))\n",
        "print(len(unique_words),len(set(stem_of_lem)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPUQ9pcWNJkB",
        "outputId": "a645c1ff-e616-4b56-8793-acb860ccf093"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87819 66835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem_of_stem = []\n",
        "\n",
        "for i in all_words:\n",
        "  lem_of_stem.append(lemmatizer.lemmatize(ps.stem(i)))\n",
        "print(len(unique_words),len(set(lem_of_stem)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSmgerY1Io2L",
        "outputId": "0dc8fcf6-87f3-4a9c-ccf6-f03dffe7fe30"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87819 66818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKhr8YfGIo4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lem = [lemmatizer.lemmatize(i) for i in all_words]"
      ],
      "metadata": {
        "id": "nWoezB7wIo6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}